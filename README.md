# House-Prices-Advanced-Regression-Techniques
Kaggle Competition : House Prices: Advanced Regression Techniques

Rank: Top 6% which is 311 out of 5196 candidates.

PROBLEM STATEMENT

Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.
With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.

GOAL
The Ultimate goal of this project is to train a model based on the given data to predict the house price as accurate as possible evaluated by the Kaggle Leaderboard. 

MODELS

There are six models that I have trained on training data and test it on testing data. Following are the models that I have trained:

•	Linear Model: Lasso Regression

•	Random Forest Regressor

•	XGBoost Regressor

•	Support Vector Regressor

•	Simple Stacking Model: Averaged Models

•	Stacking Regressor

Best Model: Simple Stacking Model: Averaged Models

Detailed Analysis: Project Report.pdf

RESULT

RMLSE Value: 0.11934

